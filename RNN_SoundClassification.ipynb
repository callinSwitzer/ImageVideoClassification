{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callin Switzer\n",
    "### Use RNN to process sounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from scipy import signal\n",
    "import itertools as it\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.io\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "# Neural net libs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "\n",
    "print(sys.version, \"\\n\")\n",
    "print(\"last run on \" + str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def windowsOrMacDirectories():\n",
    "    \"\"\" Sets base directories for win or mac\n",
    "\n",
    "       \n",
    "    \"\"\"\n",
    "    if os.environ['COMPUTERNAME'] == 'SHEALMACLEARN':\n",
    "        DropboxDirect = os.path.join(\"D:\\Dropbox\")\n",
    "#     elif sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):\n",
    "#         # this excludes your current terminal \"/dev/tty\"\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "        DropboxDirect = os.path.join(\"/Users/cswitzer/Dropbox\")\n",
    "    else:\n",
    "        raise EnvironmentError('Unknown computer platform')\n",
    "    \n",
    "    baseDir = os.getcwd()\n",
    "    dataDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehData')\n",
    "    figDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehFigs')\n",
    "    return baseDir, dataDir, figDir\n",
    "\n",
    "\n",
    "baseDir, dataDir, figDir = windowsOrMacDirectories()\n",
    "print(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMyFile(filename):\n",
    "    \n",
    "    '''Read in csv 10x faster than pandas'''\n",
    "    \n",
    "    tmpdta = []\n",
    " \n",
    "    with open(filename, newline=\"\\n\") as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile, delimiter=' ', quoting=csv.QUOTE_NONNUMERIC)\n",
    "        for row in csvReader:\n",
    "            tmpdta.append(row)\n",
    " \n",
    "    return(pd.DataFrame(np.transpose(tmpdta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset that was pre-classified\n",
    "buzzClassDataDir = os.path.join(\"D:\\Dropbox\\SonicationBehavior\\SonBehData\\BuzzPartClassification\")\n",
    "buzzClass = pd.read_csv(os.path.join(buzzClassDataDir, 'BuzzClassifications.csv'))\n",
    "print(buzzClass.shape)\n",
    "buzzClass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all data into a single dataframe\n",
    "bigList = []\n",
    "freqSpec = []\n",
    "for ii in range(buzzClass.shape[0]):\n",
    "    tmp = readMyFile(buzzClass.fileName[ii])\n",
    "    \n",
    "#     # pad with 0's\n",
    "#     tmp = readMyFile(buzzClass.fileName[ii])\n",
    "#     pad = np.arange(tmp.iloc[-1,0],tmp.iloc[-1,0]+ 0.02 - np.mean(np.diff(tmp.iloc[:,0])),  np.mean(np.diff(tmp.iloc[:,0])))\n",
    "#     zx = np.repeat(0, len(pad))\n",
    "#     pdff = pd.DataFrame( data = {\"0\":pad, \"1\":zx} )\n",
    "#     pdff.columns = tmp.columns\n",
    "\n",
    "#     tmp = pd.concat([tmp, pdff]).reset_index(drop = True)\n",
    "    \n",
    "    # calculate rolling variance\n",
    "    tmp[\"varia\"] = pd.Series((tmp.iloc[:,1] - np.mean(tmp.iloc[:,1]))).rolling(int(2000), center = True, min_periods = 1).var().tolist()\n",
    "    \n",
    "    # calculate frequency spectrum\n",
    "    f, t, Sxx = signal.spectrogram(tmp.iloc[:,1], 200000, noverlap = 900, nperseg = 1000)\n",
    "    Sxx = Sxx[0:50, :]\n",
    "    #scale\n",
    "    Sxx = Sxx - np.min(Sxx)\n",
    "    Sxx = Sxx / np.max(Sxx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    freqSpec.append(pd.DataFrame(np.transpose(Sxx)))\n",
    "    \n",
    "    # add classes to data\n",
    "    tmp[\"buzz\"] = 0\n",
    "    tmp.loc[buzzClass.buzz1[ii]:buzzClass.buzz2[ii], \"buzz\"] = 1\n",
    "    if(np.mod(ii, 10)) == 0:\n",
    "        print(ii)\n",
    "    \n",
    "    tmp[\"filename\"] = buzzClass.fileName[ii]\n",
    "    bigList.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(bigList)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index=str, columns={1: \"acc\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "df['acc_scaled'] = df.groupby('filename').acc.transform(lambda x: minmax_scale(x.astype(float), feature_range = (-1,1)))\n",
    "\n",
    "# from sklearn.preprocessing import robust_scale\n",
    "# df['acc_scaled'] = df.groupby('filename').acc.transform(lambda x: scale(x.astype(float)))\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.plot(np.array(df.iloc[0:200000, 3]))\n",
    "\n",
    "ss = 3\n",
    "\n",
    "y1 = np.array(df.iloc[0:200000, 3])*ss - 0.5*ss\n",
    "xx = np.linspace(0, len(y1) / 200000,num = len(y1) )\n",
    "y2 = np.array(df.iloc[0:200000, 5])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (10,4))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Hide the right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.plot(xx, y2, linewidth = 0.9, c = 'black')\n",
    "ax.fill_between(xx,y1,-0.5*ss, alpha = 0.5, linewidth = 0)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Scaled Accleration\")\n",
    "#plt.xticks([])\n",
    "#plt.yticks([])\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"NNSeq1.png\"), dpi = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(df.loc[:, \"buzz\"].values)\n",
    "X =  pd.DataFrame(df.loc[:, \"acc_scaled\"].values)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add windows\n",
    "for s in np.arange(1, 500):\n",
    "    X['shift_{}'.format(s)] = X[0].shift(s)\n",
    "    X['shift_{}'.format(s)] = X[0].shift(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index=  int(0.8*X.shape[0])\n",
    "\n",
    "train_x = X[:split_index].copy()\n",
    "test_x = X[split_index:].copy()\n",
    "\n",
    "train_y = Y[:split_index].copy()\n",
    "test_y = Y[split_index:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.iloc[:, 0] = train_y.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_x.dropna().drop(0, axis=1)\n",
    "y_train = train_x.dropna()[[0]]\n",
    "\n",
    "X_test = test_x.dropna().drop(0, axis=1)\n",
    "y_test = test_y.dropna()[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(X_train.iloc[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test= X_test.values\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.layers import BatchNormalization\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(patience=5, \n",
    "                          verbose=1, mode='auto', min_delta = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fully connected network with on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], activation='tanh'))\n",
    "model.add(Dense(56, activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(40, activation='tanh'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(40, activation='tanh'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=2**16, \n",
    "                    callbacks = [earlystop], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'], c = \"orange\")\n",
    "plt.title('Neural network loss and accuracy')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(history.history['binary_accuracy'], c = \"purple\")\n",
    "plt.legend(['train_loss', 'train_acc'], loc='center')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.array(y_test)[0:50000], ((np.array(pred) > 0.5) * 1)[0:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train[0:50000, 0])\n",
    "plt.plot(np.array(y_train)[0:50000] + 1.1, c= 'pink')\n",
    "plt.plot(np.array(pred)[0:50000]+ 1.1, c= 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train[0:50000, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
