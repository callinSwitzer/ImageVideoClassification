{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callin Switzer\n",
    "### Use nn to process sounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "from scipy import signal\n",
    "\n",
    "print(sys.version, \"\\n\")\n",
    "\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def windowsOrMacDirectories():\n",
    "    \"\"\" Sets base directories for win or mac\n",
    "\n",
    "       \n",
    "    \"\"\"\n",
    "    if os.environ['COMPUTERNAME'] == 'SHEALMACLEARN':\n",
    "        DropboxDirect = os.path.join(\"D:\\Dropbox\")\n",
    "#     elif sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):\n",
    "#         # this excludes your current terminal \"/dev/tty\"\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "        DropboxDirect = os.path.join(\"/Users/cswitzer/Dropbox\")\n",
    "    else:\n",
    "        raise EnvironmentError('Unknown computer platform')\n",
    "    \n",
    "    baseDir = os.getcwd()\n",
    "    dataDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehData')\n",
    "    figDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehFigs')\n",
    "    return baseDir, dataDir, figDir\n",
    "\n",
    "\n",
    "baseDir, dataDir, figDir = windowsOrMacDirectories()\n",
    "print(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMyFile(filename):\n",
    "    \n",
    "    '''Read in csv 10x faster than pandas'''\n",
    "    \n",
    "    tmpdta = []\n",
    " \n",
    "    with open(filename, newline=\"\\n\") as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile, delimiter=' ', quoting=csv.QUOTE_NONNUMERIC)\n",
    "        for row in csvReader:\n",
    "            tmpdta.append(row)\n",
    " \n",
    "    return(pd.DataFrame(np.transpose(tmpdta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset that was pre-classified\n",
    "buzzClassDataDir = os.path.join(\"D:\\Dropbox\\SonicationBehavior\\SonBehData\\BuzzPartClassification\")\n",
    "buzzClass = pd.read_csv(os.path.join(buzzClassDataDir, 'BuzzClassifications.csv'))\n",
    "print(buzzClass.shape)\n",
    "buzzClass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all data into a single dataframe\n",
    "bigList = []\n",
    "freqSpec = []\n",
    "for ii in range(buzzClass.shape[0]):\n",
    "    tmp = readMyFile(buzzClass.fileName[ii])\n",
    "    \n",
    "    # pad with 0's\n",
    "    tmp = readMyFile(buzzClass.fileName[ii])\n",
    "#     pad = np.arange(tmp.iloc[-1,0],tmp.iloc[-1,0]+ 0.02 - np.mean(np.diff(tmp.iloc[:,0])),  np.mean(np.diff(tmp.iloc[:,0])))\n",
    "#     zx = np.repeat(0, len(pad))\n",
    "#     pdff = pd.DataFrame( data = {\"0\":pad, \"1\":zx} )\n",
    "#     pdff.columns = tmp.columns\n",
    "\n",
    "#     tmp = pd.concat([tmp, pdff]).reset_index(drop = True)\n",
    "    \n",
    "    # calculate rolling variance\n",
    "    tmp[\"varia\"] = pd.Series((tmp.iloc[:,1] - np.mean(tmp.iloc[:,1]))).rolling(int(2000), center = True, min_periods = 1).var().tolist()\n",
    "    \n",
    "    # calculate frequency spectrum\n",
    "    f, t, Sxx = signal.spectrogram(tmp.iloc[:,1], 200000, noverlap = 900, nperseg = 1000)\n",
    "    Sxx = Sxx[0:50, :]\n",
    "    #scale\n",
    "    Sxx = Sxx - np.min(Sxx)\n",
    "    Sxx = Sxx / np.max(Sxx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    freqSpec.append(pd.DataFrame(np.transpose(Sxx)))\n",
    "    \n",
    "    # add classes to data\n",
    "    tmp[\"buzz\"] = 0\n",
    "    tmp.loc[buzzClass.buzz1[ii]:buzzClass.buzz2[ii], \"buzz\"] = 1\n",
    "    if(np.mod(ii, 10)) == 0:\n",
    "        print(ii)\n",
    "    \n",
    "    tmp[\"filename\"] = buzzClass.fileName[ii]\n",
    "    bigList.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(bigList)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.iloc[0:20000, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler((0,1))\n",
    "mm.fit(df.iloc[:, 1].values.reshape(-1, 1))\n",
    "df[\"scaledBuzz\"] = mm.transform(df.iloc[:, 1].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "subSamp = np.arange(0, 20000, step = 10)# np.arange(0, df.shape[0], step = 5)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(np.array(df.index[subSamp]), np.array(df.iloc[subSamp,5]))\n",
    "#plt.scatter(df.index[subSamp], df.iloc[subSamp,2]*10, s = 0.5, c = df.iloc[subSamp,3])\n",
    "plt.show()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "subSamp = np.arange(0, df.shape[0], step = 10)# np.arange(0, df.shape[0], step = 5)\n",
    "df = df.iloc[subSamp, :]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Finished Data cleaning\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from : https://gist.github.com/jkleint/1d878d0401b28b281eb75016ed29f2ee\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# Example of using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction.\n",
    "# \"\"\"\n",
    "\n",
    "from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "def make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n",
    "    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n",
    "    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n",
    "    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n",
    "    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n",
    "      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; each instance is\n",
    "      a 2D array of shape ``(window_size, nb_input_series)``.  For example, for `window_size` = 3 and `nb_input_series` = 1 (a\n",
    "      single timeseries), one instance could be ``[[0], [1], [2]]``. See ``make_timeseries_instances()``.\n",
    "    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n",
    "      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n",
    "      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n",
    "      in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n",
    "    :param int filter_length: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n",
    "      each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed\n",
    "      to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window\n",
    "      dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n",
    "      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "    :param int nb_filter: The number of different filters to learn (roughly, input patterns to recognize).\n",
    "    \"\"\"\n",
    "    model = Sequential((\n",
    "        # The first conv layer learns `nb_filter` filters (aka kernels), each of size ``(filter_length, nb_input_series)``.\n",
    "        # Its output will have shape (None, window_size - filter_length + 1, nb_filter), i.e., for each position in\n",
    "        # the input timeseries, the activation of each filter at that position.\n",
    "        \n",
    "        #Conv1D(activation=\"relu\", filters=4, kernel_size=5)\n",
    "        Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n",
    "        MaxPooling1D(),     # Downsample the output of convolution by 2X.\n",
    "        Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu'),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='sigmoid'),     # For binary classification, change the activation to 'sigmoid'\n",
    "    ))\n",
    "    #model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    # To perform (binary) classification instead:\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_timeseries_instances(timeseries, seqLabels, window_size):\n",
    "    \"\"\"Make input features and prediction targets from a `timeseries` for use in machine learning.\n",
    "    :return: A tuple of `(X, y, q)`.  `X` are the inputs to a predictor, a 3D ndarray with shape\n",
    "      ``(timeseries.shape[0] - window_size, window_size, timeseries.shape[1] or 1)``.  For each row of `X`, the\n",
    "      corresponding row of `y` is the next value in the timeseries.  The `q` or query is the last instance, what you would use\n",
    "      to predict a hypothetical next (unprovided) value in the `timeseries`.\n",
    "    :param ndarray timeseries: Either a simple vector, or a matrix of shape ``(timestep, series_num)``, i.e., time is axis 0 (the\n",
    "      row) and the series is axis 1 (the column).\n",
    "    :param int window_size: The number of samples to use as input prediction features (also called the lag or lookback).\n",
    "    \"\"\"\n",
    "    timeseries = np.asarray(timeseries)\n",
    "    assert 0 < window_size < timeseries.shape[0]\n",
    "    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n",
    "    y = seqLabels\n",
    "    q = np.atleast_3d([timeseries[-window_size:]])\n",
    "    return X, y, q\n",
    "\n",
    "\n",
    "def evaluate_timeseries(timeseries, seqLabels, window_size, epochs=100):\n",
    "    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n",
    "    as input features and evaluate its performance.\n",
    "    :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n",
    "    :param int window_size: The number of previous timeseries values to use to predict the next.\n",
    "    \"\"\"\n",
    "    filter_length = 5\n",
    "    nb_filter = 4\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T       # Convert 1D vectors to 2D column vectors\n",
    "\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "    print('\\n\\nTimeseries ({} samples by {} series):\\n'.format(nb_samples, nb_series), timeseries)\n",
    "    model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n",
    "    print('\\n\\nModel with input size {}, output size {}, {} conv filters of length {}'.format(model.input_shape, model.output_shape, nb_filter, filter_length))\n",
    "    model.summary()\n",
    "\n",
    "    X, y, q = make_timeseries_instances(timeseries, seqLabels, window_size)\n",
    "    print('\\n\\nInput features:', X, '\\n\\nOutput labels:', y, '\\n\\nQuery vector:', q, sep='\\n')\n",
    "    test_size = int(0.3 * nb_samples)           # In real life you'd want to use 0.2 - 0.5\n",
    "    train_size = nb_samples - test_size\n",
    "    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-(test_size + window_size)], y[train_size - window_size: -window_size]\n",
    "    history= model.fit(X_train, y_train, epochs=epochs, batch_size=2000, validation_data=(X_test, y_test))\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    return(pred, X_train, X_test, y_train, y_test, model, history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df.iloc[:, 5]\n",
    "seqLabels = df.iloc[:, 3]\n",
    "\n",
    "ts_length = df.shape[0]\n",
    "window_size = 1000\n",
    "\n",
    "print('\\nSimple single timeseries vector prediction')\n",
    "pred, X_train, X_test, y_train, y_test, model, history = evaluate_timeseries(timeseries,seqLabels, window_size, epochs = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train for more epochs\n",
    "history= model.fit(X_train, y_train, epochs=100, batch_size=2000, validation_data=(X_test, y_test))\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'], c = \"orange\")\n",
    "plt.title('Neural network loss and accuracy')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(history.history['binary_accuracy'], c = \"purple\")\n",
    "plt.legend(['train_loss', 'train_acc'], loc='center')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.array(y_test)[0:50000], ((np.array(pred) > 0.5) * 1)[0:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train[0:20000,0, -1])\n",
    "plt.plot(np.array(y_train)[0:20000] + 1.1, c= 'pink')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=[20, 10])\n",
    "plt.plot(X_test[0:50000,0, -1])\n",
    "plt.plot(np.array(y_test)[0:50000] + 1.1, c= 'pink')\n",
    "plt.plot(((np.array(pred) > 0.5) * 1)[0:50000] + 1, c= 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "### 1D convolution on spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add padding to beginning of dataset\n",
    "\n",
    "df = pd.concat(bigList)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "mm = MinMaxScaler((0,1))\n",
    "mm.fit(df.iloc[:, 1].values.reshape(-1, 1))\n",
    "df[\"scaledBuzz\"] = mm.transform(df.iloc[:, 1].values.reshape(-1, 1))\n",
    "\n",
    "samplingFreq = 200000\n",
    "df[\"time\"] = df.index / samplingFreq\n",
    "\n",
    "\n",
    "seq = df.loc[:,\"scaledBuzz\"]\n",
    "\n",
    "\n",
    "\n",
    "xx = df.loc[:, \"time\"]\n",
    "\n",
    "# add padding\n",
    "padLength = 100000\n",
    "s2 = np.hstack([np.zeros(padLength)+np.mean(seq),seq,np.zeros(padLength)+np.mean(seq)])\n",
    "\n",
    "plt.figure(figsize=[20, 10])\n",
    "nperS = 3000\n",
    "f, t, Sxx = signal.spectrogram(np.array(s2), fs =samplingFreq, noverlap = 2500, nperseg = nperS, nfft = 10000)\n",
    "Sxx = Sxx[0:100, :]\n",
    "f = f[0:100]\n",
    "\n",
    "\n",
    "\n",
    "# now resize to fit original data\n",
    "\n",
    "t = t - (padLength / samplingFreq)\n",
    "keepTime = (t >= np.min(xx)) & (t <= np.max(xx))\n",
    "t = t[keepTime]\n",
    "Sxx = Sxx[:, keepTime]\n",
    "\n",
    "plt.pcolormesh(t[0:1000], f, Sxx[:, 0:1000])\n",
    "plt.ylim(0,1000)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.plot(xx[0:500000], (seq[0:500000]*300) + 250, alpha = 0.3, c = 'orange')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that I've got the spectrum fixed, I'll try some other methods, before NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "bb = resize(Sxx, output_shape = [100, df.shape[0]], order = 1, mode = 'reflect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = [20, 10])\n",
    "plt.imshow(bb[:, 0:800000], aspect = \"auto\", origin = 'lower')\n",
    "plt.plot((df.loc[0:800000, \"scaledBuzz\"])*10 -30)\n",
    "plt.plot((df.loc[0:800000, \"varia\"])*750 -20)\n",
    "plt.plot((df.loc[0:800000, \"varia\"]>0.001)* 20)\n",
    "plt.plot((df.loc[0:800000, \"buzz\"])* 20)\n",
    "#plt.axes(frameon = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.DataFrame(np.transpose(bb))\n",
    "dd = pd.concat([df,cc], axis = 1 )\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(cc), aspect = \"auto\", origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build test/train sets\n",
    "np.random.seed(1235999)\n",
    "trainSamps = np.random.choice(np.unique(dd.filename), \n",
    "                              size = int(0.75*len(np.unique(dd.filename))),\n",
    "                             replace = False)\n",
    "\n",
    "\n",
    "\n",
    "train = dd[dd['filename'].isin(trainSamps)]\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "\n",
    "test = dd[~dd['filename'].isin(trainSamps)]\n",
    "test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain= np.array(train[\"buzz\"])\n",
    "Xtrain = np.array(train.drop([\"buzz\", \"filename\", \"time\", \"scaledBuzz\"], axis = 1).iloc[:, 2:])\n",
    "\n",
    "Ytest= np.array(test[\"buzz\"])\n",
    "Xtest = np.array(test.drop([\"buzz\", \"filename\", \"time\", \"scaledBuzz\"], axis = 1).iloc[:, 2:])\n",
    "\n",
    "\n",
    "# scale each column -- save scaling factors\n",
    "dfMin = Xtrain[:,1:].min(axis = 0)\n",
    "dfMax =  Xtrain[:,1:].max(axis = 0)\n",
    "\n",
    "varMin = Xtrain[:,0].min()\n",
    "varMax =  Xtrain[:,0].max()\n",
    "\n",
    "Xtrain[:,1:] =  Xtrain[:,1:] - dfMin\n",
    "Xtrain[:,1:] =  Xtrain[:,1:] / dfMax\n",
    "Xtrain[:,0] =  Xtrain[:,0] - varMin\n",
    "Xtrain[:,0] =  Xtrain[:,0] / varMax\n",
    "\n",
    "Xtest[:,1:] =  Xtest[:,1:] - dfMin\n",
    "Xtest[:,1:] =  Xtest[:,1:] / dfMax\n",
    "Xtest[:,0] =  Xtest[:,0] - varMin\n",
    "Xtest[:,0] =  Xtest[:,0] / varMax\n",
    "\n",
    "plt.imshow(np.array(np.transpose(Xtrain)), aspect='auto')\n",
    "\n",
    "#plt.plot(Xtrain[:,0]*100, c= 'red', markersize= 1000)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train.iloc[:,1])\n",
    "# plt.plot(Xtrain[:,0]*5, c= 'red', markersize= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = time.time()\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.LinearSVC(dual = False)\n",
    "clf.fit(Xtrain[:, 0].reshape(-1, 1), Ytrain)  \n",
    "preds = clf.predict(Xtest[:, 0].reshape(-1, 1))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(clf.predict(Xtrain[:, 0].reshape(-1, 1)), Ytrain))\n",
    "print(accuracy_score(preds, Ytest))\n",
    "print(time.time() - stt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "stt = time.time()\n",
    "forest = rfc(n_jobs = -1, class_weight=\"balanced\")\n",
    "forest.fit(Xtrain[:,0].reshape(-1, 1), Ytrain)\n",
    "print(time.time() - stt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = forest.predict(Xtest.reshape(-1, 1))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(forest.predict(Xtrain[:,0].reshape(-1, 1)), Ytrain))\n",
    "accuracy_score(preds, Ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(forest.predict(Xtrain), Ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efsfees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = (Xtest[:,0] > 0.001)*1\n",
    "print(accuracy_score(p2, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(p2, Ytest)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(p2, Ytest)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal practice\n",
    "samplingFreq = 200000\n",
    "\n",
    "xx = np.linspace(0, 1, num = samplingFreq)\n",
    "seq = np.sin(250 * 2 * np.pi * xx + (30*np.sin(2*np.pi* 3 * xx))) #+ np.sin(800*2*np.pi* xx)\n",
    "\n",
    "seq[40000:80000] = 0\n",
    "\n",
    "mm = MinMaxScaler((0,1))\n",
    "mm.fit(seq.reshape(-1, 1))\n",
    "s1= mm.transform(seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# add padding\n",
    "padLength = 100000\n",
    "s2 = np.hstack([np.zeros(padLength) ,s1.reshape(-1,),np.zeros(padLength) - 10])\n",
    "\n",
    "plt.figure(figsize=[20, 10])\n",
    "nperS = 11000\n",
    "f, t, Sxx = signal.spectrogram(np.array(s2), fs =samplingFreq, noverlap = 3000, nperseg = 3500)\n",
    "Sxx = Sxx[0:50, :]\n",
    "f = f[0:50]\n",
    "\n",
    "plt.pcolormesh(t, f, Sxx)\n",
    "plt.ylim(0,400)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.plot(xx, (seq*30) + 250)\n",
    "plt.show()\n",
    "\n",
    "# now resize to fit original data\n",
    "\n",
    "t = t - (padLength / samplingFreq)\n",
    "keepTime = (t >= np.min(xx)) & (t <= np.max(xx))\n",
    "t = t[keepTime]\n",
    "Sxx = Sxx[:, keepTime]\n",
    "\n",
    "plt.pcolormesh(t, f, Sxx)\n",
    "plt.ylim(0,400)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.plot(xx, (seq*30) + 250)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal practice\n",
    "samplingFreq = 200000\n",
    "\n",
    "xx = np.linspace(0, 1, num = samplingFreq)\n",
    "seq = np.sin(100 * 2 * np.pi * xx + (10*np.sin(2*np.pi* 3 * xx))) #+ np.sin(800*2*np.pi* xx)\n",
    "\n",
    "seq[40000:80000] = 0\n",
    "\n",
    "from scipy import signal\n",
    "plt.figure(figsize=[20, 10])\n",
    "nperS = 16000\n",
    "f, t, Sxx = signal.spectrogram(np.array(seq), 200000, noverlap = 1550, nperseg = nperS)\n",
    "Sxx = Sxx[0:90,:]\n",
    "f = f[0:90]\n",
    "plt.pcolormesh(t, f, Sxx)\n",
    "plt.ylim(0,1000)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(xx , (seq*100))\n",
    "\n",
    "\n",
    "# now resize to fit original data\n",
    "plt.plot(t, Sxx[15, :]*10000000)\n",
    "print(np.min(t), np.max(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.transpose([t, Sxx[20, :]*100]))\n",
    "min(t), max(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = pd.concat(freqSpec)\n",
    "plt.imshow((FS.transpose()).iloc[:,  0:500, ], aspect = \"auto\", origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subSamp = np.linspace(0, df.shape[0]-1, num = t.shape[0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[subSamp, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x2[x2 < 2.5], y2[x2 < 2.5]*300)\n",
    "\n",
    "x2 = (np.arange() / 20000)\n",
    "y2 = df2.loc[:,\"scaledBuzz\"]\n",
    "plt.plot(x2[x2 < 2.5], y2[x2 < 2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
